# Remove not-alphanumber characters
import re
re.sub(r'[^a-zA-Z0-9]+', ' ',string) 

# Replace words
string = string.replace("things needed to be replaced","things replaced to be")

# Stem words
import nltk
from nltk.stem.snowball import SnowballStemmer
stem_=SnowballStemmer("english")
stem_.stem('word needed to be stemed')

# Lemmatize words
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize('word needed to be lemmatized')

# Remove stop words
from nltk.corpus import stopwords
stop_words = list(stopwords.words('english'))
#remove stop words
string = " ".join(item for item in string.split() if item.lower() not in stop_words) 
   
# Tokenize words
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
word_tokenize(text)

# web scrapping
import requests
from bs4 import BeautifulSoup
#load a page

results = requests.get("{the webpage with https:// start}")
reformat_results = BeautifulSoup(results.content, 'lxml')
print(reformat_results.prettify())

